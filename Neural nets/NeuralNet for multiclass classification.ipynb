{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цій практичній роботі ми спробуємо реалізувати нейронну мережу з двох шарів (прихований і вихідний). Запропонований підхід стане заготовкою для реалізації наступних оптимізацій: MBGD, ADAM та регуляризації. \n",
    "\n",
    "Сьогодні ж вам пропонується додати до цього класу підтримку довільної кількості шарів та нейронів в них (наприклад, передавати їх параметром в конструктор, як це робиться в MLPClassifier за допомогою hidden_layer_sizes). Також потрібно передбачити можливість ранньої зупинки ітераційного процесу, якщо значення штрафної функції не покращуватиметься протягом певної кількості ітерацій. Наприклад, якщо протягом $k$ ітерацій штрафна функція за модулем не стане меншою, ніж на поточному кроці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import sklearn.linear_model\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface(cls, x_1, x_2, ax=None, threshold=0.5, contourf=False):\n",
    "    xx1, xx2 = np.meshgrid(np.linspace(x_1.min(), x_1.max(), 100), \n",
    "                           np.linspace(x_2.min(), x_2.max(), 100))\n",
    "\n",
    "    X_pred = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "    pred = cls.predict_proba(X_pred)[:, 0]\n",
    "    Z = pred.reshape((100, 100))\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.contour(xx1, xx2, Z, levels=[threshold], colors='black')\n",
    "    ax.set_xlim((x_1.min(), x_1.max()))\n",
    "    ax.set_ylim((x_2.min(), x_2.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxNeuralNet:\n",
    "\n",
    "  def __init__(self, layer_dims, normalize=True, learning_rate=0.01, num_iter=30000, precision=None):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.num_iter = num_iter\n",
    "    self.normalize = normalize\n",
    "    self.layer_dims = layer_dims\n",
    "    self.precision = precision\n",
    "\n",
    "  def __normalize(self, X, mean=None, std=None):\n",
    "    n = X.shape[0]\n",
    "\n",
    "    if mean is None:\n",
    "      mean = np.mean(X, axis=1).reshape((n, 1))\n",
    "\n",
    "    if std is None:\n",
    "      std = np.std(X, axis=1).reshape((n, 1))\n",
    "      \n",
    "    X_new = (X - mean) / std**2\n",
    "    \n",
    "    return X_new, mean, std\n",
    "\n",
    "  def __sigmoid(self, Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "  def __sigmoid_derivative(self, Z):\n",
    "    s = self.__sigmoid(Z)\n",
    "    return s*(1 - s)\n",
    "\n",
    "  def __relu(self, Z):\n",
    "    Z = np.array(Z, copy=True)\n",
    "    Z[Z < 0] = 0.001\n",
    "    return Z\n",
    "\n",
    "  def __relu_derivative(self, Z):\n",
    "    dZ = np.ones(Z.shape)\n",
    "    dZ[Z <=0 ] = 0\n",
    "    return dZ\n",
    "\n",
    "  def __tanh(self, Z):\n",
    "    return np.tanh(Z)\n",
    "\n",
    "  def __tanh_derivative(self, Z):\n",
    "    return 1 / np.power(np.cosh(Z), 2)\n",
    "\n",
    "  def __softmax(self, Z):\n",
    "    eZ = np.exp(Z - np.max(Z))\n",
    "    return eZ / np.sum(eZ, axis=0, keepdims=True)\n",
    "\n",
    "  def __initialize_parameters(self):\n",
    "    layer_dims = self.layer_dims\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "\n",
    "    for l in range(1, L):\n",
    "      parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "      print(parameters['W' + str(l)].shape)\n",
    "      parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "    \n",
    "    self.parameters = parameters\n",
    "\n",
    "  def __forward_linear_activation(self, A_prev, W, b, activation):\n",
    "\n",
    "    # linear forward\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    linear_cache = (A_prev, W, b)\n",
    "\n",
    "    # activation forward\n",
    "    if activation == 'sigmoid':\n",
    "      A = self.__sigmoid(Z)\n",
    "    \n",
    "    if activation == 'relu':\n",
    "      A = self.__relu(Z)\n",
    "    \n",
    "    if activation == 'softmax':\n",
    "      A = self.__softmax(Z)\n",
    "\n",
    "    if activation == 'tanh':\n",
    "      A = self.__tanh(Z)\n",
    "    \n",
    "    activation_cache = Z\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "  def __multilayer_forward(self, X):\n",
    "    parameters = self.parameters\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(1, L):\n",
    "      A_prev = A\n",
    "      A, cache = self.__forward_linear_activation(\n",
    "        A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], activation='tanh')\n",
    "      caches.append(cache)\n",
    "\n",
    "    AL, cache = self.__forward_linear_activation(\n",
    "      A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], activation='softmax')\n",
    "    caches.append(cache)\n",
    "\n",
    "    assert(AL.shape == (10, X.shape[1]))\n",
    "    \n",
    "    return AL, caches\n",
    "\n",
    "  def __backward_linear_activation(self, dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    # activation backward\n",
    "    Z = activation_cache\n",
    "    A_prev, W, b = linear_cache\n",
    "    \n",
    "    if activation == 'sigmoid':\n",
    "      dZ = dA * self.__sigmoid_derivative(Z)\n",
    "\n",
    "    if activation == 'relu':\n",
    "      dZ = dA * self.__relu_derivative(Z)\n",
    "    \n",
    "    if activation == 'tanh':\n",
    "      dZ = dA * self.__tanh_derivative(Z)\n",
    "\n",
    "    # linear backward\n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1 / m * np.dot(dZ, A_prev.T)\n",
    "    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "  def __multilayer_backward(self, X, Y, caches):\n",
    "    grads = {}\n",
    "    AL = X\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "   \n",
    "    \n",
    "    linear_cache, activation_cache = caches[L-1]\n",
    "    A_prev, W, b = linear_cache\n",
    "    \n",
    "    dZ = AL - Y\n",
    "    m = AL.shape[1]\n",
    "    grads[\"dW\" + str(L)] = 1 / m * np.dot(dZ, A_prev.T)\n",
    "    grads[\"db\" + str(L)] = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    grads[\"dA\" + str(L-1)] = np.dot(W.T, dZ)\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "      current_cache = caches[l]\n",
    "      dA_prev_temp, dW_temp, db_temp = \\\n",
    "        self.__backward_linear_activation(grads[\"dA\" + str(l + 1)], current_cache, activation='tanh')\n",
    "      grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "      grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "      grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n",
    "\n",
    "  def compute_cost(self, A, Y):\n",
    "    J = -np.mean(Y.T * np.log(A.T+ 1e-8))\n",
    "    return J\n",
    "\n",
    "  def cross_entropy(self, A, Y):\n",
    "    return - np.sum(Y * np.log(A), axis=1)\n",
    "\n",
    "  def __update_parameters(self, grads):\n",
    "    parameters = self.parameters\n",
    "    learning_rate = self.learning_rate\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(L):\n",
    "      parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "      parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "\n",
    "    self.parameters = parameters\n",
    "\n",
    "  def fit(self, X_vert, Y_vert, print_cost=True):\n",
    "\n",
    "    X, Y = X_vert.T, Y_vert.T\n",
    "\n",
    "    if self.normalize:\n",
    "      X, self.__mean, self.__std = self.__normalize(X)\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    self.__initialize_parameters()\n",
    "\n",
    "    for i in range(0, self.num_iter):\n",
    "\n",
    "      AL, caches = self.__multilayer_forward(X)\n",
    "\n",
    "      cost = self.compute_cost(AL, Y)\n",
    "\n",
    "      grads = self.__multilayer_backward(AL, Y, caches)\n",
    "\n",
    "      self.__update_parameters(grads)\n",
    "\n",
    "      if print_cost and i % 10 == 0:\n",
    "        print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "      if print_cost and i % 10 == 0:\n",
    "        costs.append(cost)\n",
    "\n",
    "      if len(costs) > 1 and self.precision != None and np.abs(costs[-2] - costs[-1]) < self.precision:\n",
    "        print('Stopping gradient descent ...')\n",
    "        break\n",
    "\n",
    "    if print_cost:\n",
    "      plt.plot(costs)\n",
    "      plt.ylabel(\"Cost\")\n",
    "      plt.xlabel(\"Iteration, *100\")\n",
    "      plt.show()\n",
    "\n",
    "  def predict_proba(self, X_vert):\n",
    "    X = X_vert.T\n",
    "    if self.normalize:\n",
    "      X, _, _ = self.__normalize(X, self.__mean, self.__std)\n",
    "\n",
    "    probs = self.__multilayer_forward(X)[0]\n",
    "\n",
    "    return probs.T\n",
    "\n",
    "  def predict(self, X_vert):\n",
    "    positive_probs = self.predict_proba(X_vert)\n",
    "    return np.argmax(positive_probs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/large/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X=(42000, 784), y=(42000,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = df.drop('label', axis=1), df['label']\n",
    "print('Training set: X={}, y={}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, _, Y , _= train_test_split(X, Y.values.reshape((Y.shape[0], 1)), test_size = 0.9, random_state=10)\n",
    "#print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y.values.reshape((Y.shape[0], 1)), test_size = 0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_e = encoder.fit_transform(Y_train).toarray()\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = SoftmaxNeuralNet(layer_dims = [784, 60, 10], normalize = False, learning_rate = 0.1, num_iter = 450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 784)\n",
      "(10, 60)\n",
      "Cost after iteration 0: 0.230175\n",
      "Cost after iteration 10: 0.228661\n",
      "Cost after iteration 20: 0.225947\n",
      "Cost after iteration 30: 0.220187\n",
      "Cost after iteration 40: 0.208723\n",
      "Cost after iteration 50: 0.190049\n",
      "Cost after iteration 60: 0.167515\n",
      "Cost after iteration 70: 0.146406\n",
      "Cost after iteration 80: 0.128747\n",
      "Cost after iteration 90: 0.114523\n",
      "Cost after iteration 100: 0.103120\n",
      "Cost after iteration 110: 0.093920\n",
      "Cost after iteration 120: 0.086431\n",
      "Cost after iteration 130: 0.080265\n",
      "Cost after iteration 140: 0.075123\n",
      "Cost after iteration 150: 0.070782\n",
      "Cost after iteration 160: 0.067074\n",
      "Cost after iteration 170: 0.063871\n",
      "Cost after iteration 180: 0.061076\n",
      "Cost after iteration 190: 0.058615\n",
      "Cost after iteration 200: 0.056430\n",
      "Cost after iteration 210: 0.054476\n",
      "Cost after iteration 220: 0.052719\n",
      "Cost after iteration 230: 0.051130\n",
      "Cost after iteration 240: 0.049688\n",
      "Cost after iteration 250: 0.048373\n",
      "Cost after iteration 260: 0.047170\n",
      "Cost after iteration 270: 0.046067\n",
      "Cost after iteration 280: 0.045053\n",
      "Cost after iteration 290: 0.044117\n",
      "Cost after iteration 300: 0.043252\n",
      "Cost after iteration 310: 0.042451\n",
      "Cost after iteration 320: 0.041707\n",
      "Cost after iteration 330: 0.041014\n",
      "Cost after iteration 340: 0.040367\n",
      "Cost after iteration 350: 0.039762\n",
      "Cost after iteration 360: 0.039195\n",
      "Cost after iteration 370: 0.038663\n",
      "Cost after iteration 380: 0.038161\n",
      "Cost after iteration 390: 0.037688\n",
      "Cost after iteration 400: 0.037241\n",
      "Cost after iteration 410: 0.036818\n",
      "Cost after iteration 420: 0.036416\n",
      "Cost after iteration 430: 0.036034\n",
      "Cost after iteration 440: 0.035671\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.fit(X_train, Y_train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[ 1.62434536e-02, -6.11756414e-03, -5.28171752e-03, ...,\n",
      "        -1.10657307e-02, -3.59224096e-03,  5.05381903e-03],\n",
      "       [ 1.21794090e-02, -1.94068096e-02, -8.06178212e-03, ...,\n",
      "         2.07229946e-03, -1.43403073e-02,  6.26906306e-03],\n",
      "       [ 2.99825202e-03, -1.85664142e-02, -2.15104316e-02, ...,\n",
      "        -1.95419182e-02,  1.86223746e-03, -3.82994307e-05],\n",
      "       ...,\n",
      "       [ 7.85812220e-03,  6.57456795e-03,  6.37326204e-03, ...,\n",
      "         9.56189284e-03,  1.18337456e-02,  2.18726377e-02],\n",
      "       [-1.07996566e-02, -1.49725917e-03,  1.39717091e-02, ...,\n",
      "        -7.61156529e-03,  1.28740460e-02,  6.56379966e-03],\n",
      "       [ 9.54058572e-03,  1.03352868e-03,  7.60558905e-03, ...,\n",
      "         1.26743192e-03,  1.98366136e-03,  1.17245461e-02]]), 'b1': array([[ 0.00842719],\n",
      "       [-0.04470297],\n",
      "       [ 0.0734461 ],\n",
      "       [ 0.03874039],\n",
      "       [ 0.06430759],\n",
      "       [-0.07483571],\n",
      "       [-0.02598592],\n",
      "       [ 0.01980663],\n",
      "       [-0.05008748],\n",
      "       [-0.01554188],\n",
      "       [-0.00106524],\n",
      "       [ 0.03761606],\n",
      "       [-0.0292764 ],\n",
      "       [ 0.03898748],\n",
      "       [ 0.04274984],\n",
      "       [-0.01779399],\n",
      "       [ 0.03757968],\n",
      "       [-0.02108477],\n",
      "       [-0.03392781],\n",
      "       [-0.05834322],\n",
      "       [-0.0143428 ],\n",
      "       [-0.00395765],\n",
      "       [ 0.0083452 ],\n",
      "       [-0.03058601],\n",
      "       [-0.01825792],\n",
      "       [-0.04768655],\n",
      "       [ 0.01347818],\n",
      "       [-0.01124754],\n",
      "       [-0.03562425],\n",
      "       [-0.01005351],\n",
      "       [-0.04817879],\n",
      "       [ 0.0317375 ],\n",
      "       [ 0.01880853],\n",
      "       [-0.0223157 ],\n",
      "       [-0.04067684],\n",
      "       [-0.0524547 ],\n",
      "       [ 0.03321398],\n",
      "       [ 0.0126721 ],\n",
      "       [ 0.05276988],\n",
      "       [-0.04066027],\n",
      "       [-0.00884535],\n",
      "       [-0.02066762],\n",
      "       [ 0.03510806],\n",
      "       [-0.04420952],\n",
      "       [ 0.04803298],\n",
      "       [-0.03149543],\n",
      "       [-0.0974732 ],\n",
      "       [-0.03303691],\n",
      "       [ 0.00537562],\n",
      "       [-0.01596869],\n",
      "       [ 0.03087785],\n",
      "       [ 0.02551851],\n",
      "       [ 0.02833125],\n",
      "       [ 0.04086204],\n",
      "       [-0.03875719],\n",
      "       [-0.01099717],\n",
      "       [ 0.02844392],\n",
      "       [ 0.03218665],\n",
      "       [ 0.00310431],\n",
      "       [-0.03660985]]), 'W2': array([[ 1.52837816e-01,  2.03548604e-01, -2.39468596e-01,\n",
      "         4.25533536e-01, -1.46177002e-01,  2.06460357e-01,\n",
      "         9.37019948e-02, -8.12575599e-03,  1.30745677e-01,\n",
      "         1.03581191e-01, -1.18595652e-01,  7.16183536e-02,\n",
      "        -3.23528847e-01, -1.30729119e-01, -1.94268883e-01,\n",
      "        -6.96817131e-02,  1.44220202e-01,  5.03791848e-01,\n",
      "         4.92988077e-01,  2.90989838e-01,  3.85420622e-02,\n",
      "         3.85192518e-01, -3.35848872e-02, -1.22081986e-01,\n",
      "        -4.99334745e-02, -3.38862768e-01, -2.82219078e-01,\n",
      "         3.78994361e-01,  2.97348707e-01,  1.32918839e-01,\n",
      "         1.60225242e-01,  5.88620833e-02, -3.71993765e-01,\n",
      "        -9.09730958e-02,  2.58877186e-01, -9.58446917e-02,\n",
      "         1.39759674e-02, -1.73682465e-01, -2.64772790e-02,\n",
      "         1.78042183e-01, -2.58632051e-02, -4.33092146e-01,\n",
      "         1.40288414e-01,  1.95787398e-01,  1.08249285e-01,\n",
      "         9.43429053e-03, -2.15128387e-01, -2.31079619e-01,\n",
      "        -2.85835486e-01,  8.12485641e-02,  1.99087287e-01,\n",
      "        -2.04323836e-01, -1.75918270e-01,  2.58974951e-01,\n",
      "        -1.65434698e-01,  4.94651670e-02,  2.43739113e-01,\n",
      "        -3.41266486e-01,  6.09342907e-02, -3.18275415e-01],\n",
      "       [-3.86959666e-01, -2.96458628e-01,  1.94809434e-01,\n",
      "        -2.98462983e-02,  3.16903165e-01,  6.54853443e-02,\n",
      "        -2.74302457e-01, -1.61295384e-01, -2.90023629e-02,\n",
      "        -1.34707395e-01,  2.24326519e-01, -1.27554411e-01,\n",
      "         2.82756388e-01,  3.81616367e-01,  1.32732977e-01,\n",
      "        -1.53272275e-01,  4.71998409e-01, -1.82123918e-01,\n",
      "        -1.99332350e-01, -3.37188930e-01, -3.40474136e-01,\n",
      "        -4.79622685e-02,  3.12474197e-01,  1.82372688e-01,\n",
      "        -1.74981422e-01, -9.78265241e-02,  3.01090982e-01,\n",
      "        -9.25281040e-02, -2.08376735e-01, -3.64823516e-01,\n",
      "        -3.87886610e-01, -1.03042234e-01,  1.63316770e-01,\n",
      "        -9.60759013e-02, -1.20013185e-02,  1.85422196e-01,\n",
      "        -7.93001625e-02, -2.89525568e-02,  3.46391794e-01,\n",
      "        -3.66167424e-01, -2.92108300e-01,  1.80360507e-01,\n",
      "         3.18138736e-01, -2.76237029e-01,  6.57677523e-02,\n",
      "        -2.52189370e-01,  5.17998319e-02,  1.68993415e-01,\n",
      "         5.34778166e-02,  5.26163172e-02,  5.10242810e-02,\n",
      "        -1.64547708e-02,  2.53197666e-01, -2.19220362e-01,\n",
      "         1.44235474e-01, -9.84806145e-02, -2.62399828e-01,\n",
      "         2.24557475e-01,  2.71276353e-01,  1.46609923e-01],\n",
      "       [ 2.78651111e-01,  1.43392020e-01, -3.15645474e-01,\n",
      "        -2.21689874e-01,  2.18722741e-01,  2.94226722e-01,\n",
      "        -9.98471917e-02,  8.95450724e-02,  6.44274208e-02,\n",
      "         9.23934422e-02,  5.24434360e-01, -1.32241571e-01,\n",
      "         1.88101136e-01,  4.32431670e-01,  2.55168774e-02,\n",
      "         9.10224140e-02, -2.44872171e-01,  9.59964841e-02,\n",
      "         8.59533617e-02,  2.84818157e-01, -2.55109482e-01,\n",
      "         2.42545375e-01,  2.45758270e-01,  3.36245915e-02,\n",
      "        -6.71606594e-02,  2.21696046e-01, -2.54095269e-01,\n",
      "         2.41487429e-01,  1.04711362e-01, -1.55488827e-01,\n",
      "         3.47192551e-01, -2.24390632e-01, -1.43920678e-01,\n",
      "        -1.33799026e-01,  2.48545280e-01, -1.00956994e-01,\n",
      "         3.37558846e-01,  1.03720097e-01, -1.12811343e-01,\n",
      "         1.28634079e-01, -1.41030535e-01, -6.10350303e-03,\n",
      "        -1.46237350e-01,  1.00616360e-01, -1.94998165e-01,\n",
      "         4.39548502e-01,  1.94603037e-01,  2.09628586e-01,\n",
      "        -1.88546297e-01,  1.18905059e-01,  1.08736039e-01,\n",
      "        -1.36159052e-01,  1.44121888e-01, -3.09327596e-01,\n",
      "         2.55150433e-01,  9.09581309e-02, -2.54737282e-01,\n",
      "         1.35890710e-01,  3.84583934e-01,  1.37622000e-01],\n",
      "       [ 2.76745938e-01,  3.22552657e-02,  3.13429062e-01,\n",
      "         6.00067909e-02, -8.87947514e-02, -9.38968274e-02,\n",
      "        -1.87302610e-01, -3.99725552e-01,  1.40871253e-02,\n",
      "         2.01765769e-01, -5.41652965e-02,  4.52326059e-02,\n",
      "         2.13574122e-01, -2.34119173e-01,  1.08662565e-01,\n",
      "        -2.35523687e-02, -1.02513964e-01, -7.91551975e-02,\n",
      "        -2.71481670e-01,  1.58623806e-01, -4.89467743e-01,\n",
      "         2.09580062e-01, -1.66404785e-01,  3.18415251e-01,\n",
      "        -2.02264989e-01, -1.97903048e-01,  2.62524596e-01,\n",
      "        -2.83411199e-01,  9.00228339e-02, -2.77957745e-02,\n",
      "         4.17200531e-01, -1.12224120e-01,  1.95996990e-01,\n",
      "        -1.23090853e-01,  1.89978350e-01,  1.89545319e-01,\n",
      "        -1.51620734e-01,  1.03832920e-01, -1.35569358e-01,\n",
      "         1.35719606e-01,  2.62822879e-02, -4.09343267e-01,\n",
      "         9.95740823e-02, -2.68135396e-01,  3.21272464e-01,\n",
      "         3.07531678e-01,  5.55207005e-02,  2.72846332e-01,\n",
      "        -2.38090543e-01,  1.97751520e-01, -5.29913944e-03,\n",
      "        -3.49931181e-02,  9.39229503e-02,  2.31409287e-02,\n",
      "         1.73785456e-01,  2.03938658e-01, -2.83570425e-01,\n",
      "         3.93656137e-01, -1.01524753e-01, -1.46734489e-01],\n",
      "       [-5.88992175e-02,  2.80050714e-02, -8.94943192e-02,\n",
      "        -2.32205614e-01, -6.56567052e-02, -3.54262921e-01,\n",
      "         2.69852669e-01,  2.03595626e-02, -3.36900854e-01,\n",
      "        -9.85133440e-02, -1.93663988e-01,  2.87287082e-01,\n",
      "         1.46828017e-02, -4.20211969e-03,  1.27611707e-01,\n",
      "         2.14818812e-01, -4.32248561e-02, -4.78553846e-02,\n",
      "         2.17301705e-01, -3.27802738e-01,  2.96462135e-01,\n",
      "        -3.79231893e-01, -1.16522794e-01, -4.32865550e-01,\n",
      "        -3.95672574e-02,  1.70644268e-01, -2.75042294e-01,\n",
      "        -2.77223364e-01, -2.42119449e-01, -1.41290869e-02,\n",
      "        -2.41882982e-01, -7.18515392e-02,  6.53952527e-02,\n",
      "         3.46890188e-01, -4.10917669e-01, -1.71017181e-01,\n",
      "        -7.02729799e-02,  1.68301511e-01, -3.40453255e-01,\n",
      "        -3.34901433e-02, -6.04922713e-03,  2.10397086e-01,\n",
      "        -4.04115944e-01,  5.18012486e-02, -3.05684548e-01,\n",
      "         1.51400908e-01, -3.28005567e-01, -3.24069474e-01,\n",
      "         1.19120369e-01, -4.80264719e-01, -2.41613320e-01,\n",
      "         3.86197940e-01, -1.00780912e-01, -4.29237521e-02,\n",
      "         2.45238791e-02, -4.04538542e-02,  1.19387951e-01,\n",
      "         3.17156228e-04, -8.85974145e-02,  2.15593285e-01],\n",
      "       [-1.14961866e-01,  6.73861894e-03,  2.71832765e-01,\n",
      "         2.38209694e-01, -1.69325226e-02, -1.89563888e-02,\n",
      "         3.41028139e-02,  1.96985831e-01,  2.37266006e-01,\n",
      "         1.60010533e-01, -3.05378143e-01,  3.44650614e-02,\n",
      "        -1.35959946e-01, -2.29449048e-01, -3.59431591e-01,\n",
      "        -2.93973601e-01,  4.63697177e-03, -2.12985550e-01,\n",
      "        -1.66688058e-01,  1.81849522e-01,  2.19391411e-01,\n",
      "         1.22473991e-01, -1.20972726e-01, -1.54212203e-01,\n",
      "        -1.78604948e-01, -1.57120311e-01,  1.77786811e-01,\n",
      "        -1.53779357e-01,  3.74075229e-01,  2.29936831e-01,\n",
      "        -1.45985124e-01, -7.44694058e-02, -2.98194126e-02,\n",
      "         2.19500882e-03, -1.25578366e-01,  2.14161977e-03,\n",
      "        -2.84212671e-01,  1.37979496e-01, -1.80911305e-01,\n",
      "         2.50561089e-01,  2.00306223e-01, -3.35600733e-01,\n",
      "         2.44438978e-01, -1.94970157e-02,  1.49146701e-02,\n",
      "        -6.29861554e-01, -2.01534485e-01,  9.32887182e-02,\n",
      "        -1.89182862e-01, -6.36923378e-02,  1.90963020e-01,\n",
      "         2.37646949e-02,  1.41804502e-01,  3.28606846e-01,\n",
      "        -6.46271098e-02,  1.48997054e-02,  1.72815266e-01,\n",
      "        -1.18124339e-01, -1.63194092e-01,  1.88920694e-02],\n",
      "       [-5.24881794e-02,  2.43779210e-01,  6.29619879e-02,\n",
      "        -2.02602407e-01,  3.00508378e-01, -4.88883814e-02,\n",
      "        -4.23731869e-01, -5.28242562e-02,  2.07407258e-01,\n",
      "        -4.27981324e-01,  2.27619602e-01,  2.41729655e-01,\n",
      "        -1.95601263e-01,  8.26055286e-03, -2.15755198e-01,\n",
      "         2.50576886e-01, -3.59698414e-02,  6.09596513e-02,\n",
      "         4.14139852e-01, -2.30388853e-01,  3.08204418e-01,\n",
      "         9.65164792e-02, -2.05286895e-02, -3.04979381e-01,\n",
      "         1.97284612e-01,  1.15060102e-02, -3.57991616e-01,\n",
      "        -1.07955771e-01,  1.30300404e-01, -9.67876887e-02,\n",
      "        -4.75481804e-01, -3.88444781e-02, -1.56676204e-01,\n",
      "         6.06975561e-02,  4.80497545e-01, -1.81185098e-01,\n",
      "         1.43995369e-01,  1.56565248e-01, -9.38808898e-02,\n",
      "         9.43185170e-02, -7.63718417e-02,  1.82214507e-01,\n",
      "        -2.08962493e-01,  2.12444632e-01, -3.10368335e-01,\n",
      "        -9.31194729e-02,  1.10248325e-01,  1.43385258e-01,\n",
      "         2.83137210e-01, -3.20554765e-01,  3.54126350e-01,\n",
      "         9.84209206e-02,  4.54700835e-02, -7.67200634e-02,\n",
      "         3.70453333e-01, -3.56419152e-01,  2.32940931e-01,\n",
      "        -3.90930292e-01,  3.08009897e-01,  6.20927181e-02],\n",
      "       [ 1.77294041e-01, -2.68867669e-01, -1.19540759e-03,\n",
      "         2.87842781e-01,  3.05321916e-02, -1.13933331e-01,\n",
      "         1.70789715e-01,  1.19952947e-01, -4.06383525e-01,\n",
      "        -1.75595447e-02,  1.01890880e-01, -1.69704693e-01,\n",
      "        -2.37461261e-01,  2.27246963e-01,  4.90698085e-01,\n",
      "         6.55772919e-03, -4.09902631e-02,  1.20508204e-01,\n",
      "        -3.32709613e-01,  7.68299507e-02, -1.61271106e-01,\n",
      "        -1.97039202e-01,  6.92749272e-02,  1.63649315e-01,\n",
      "         2.81848191e-01, -6.45154376e-02,  1.37777149e-01,\n",
      "         2.21403338e-01, -3.31911078e-01,  6.27411953e-02,\n",
      "         2.45048510e-01,  5.03103677e-01,  1.34773443e-01,\n",
      "        -2.98845761e-01, -2.98939895e-01, -2.21385996e-01,\n",
      "         3.23061982e-01, -2.73751775e-01,  5.77543117e-01,\n",
      "        -1.67447803e-01,  7.59948887e-02,  2.58209855e-02,\n",
      "         8.71740309e-02, -2.44803481e-01,  2.80865403e-01,\n",
      "         1.96638535e-01, -2.75048192e-01, -2.21155300e-01,\n",
      "         1.89659611e-01,  1.25100129e-01, -2.45911902e-01,\n",
      "        -4.28103601e-02, -1.88189329e-01,  6.39593876e-02,\n",
      "        -3.23191497e-01,  9.88930024e-02, -1.87495133e-02,\n",
      "         1.20131626e-01, -3.19199991e-01, -5.15199218e-01],\n",
      "       [-2.21471888e-01,  3.97616069e-02, -2.82640574e-01,\n",
      "        -1.57910807e-01, -2.81167320e-01,  3.99803201e-01,\n",
      "         2.34082760e-01,  1.23829415e-01,  2.78839903e-01,\n",
      "         9.91506099e-02, -1.85564215e-01, -2.99334358e-01,\n",
      "         1.80750580e-01, -1.96998924e-01, -2.08989010e-01,\n",
      "        -1.71197159e-01, -9.63644305e-02, -1.83787668e-01,\n",
      "        -1.20527160e-01,  1.93206345e-01,  1.80656032e-01,\n",
      "        -1.66991278e-01, -4.71569007e-02,  1.32261125e-01,\n",
      "         1.98912515e-02,  2.65393368e-01,  2.09411922e-01,\n",
      "        -1.57677637e-02,  1.01703951e-01,  1.20652970e-01,\n",
      "        -5.59909475e-02, -1.98175323e-01,  4.87314024e-02,\n",
      "        -4.65916881e-02, -6.40292520e-02,  2.52155539e-01,\n",
      "        -2.09924363e-01, -8.29637462e-02, -1.26831692e-01,\n",
      "         1.72790343e-01,  1.26560266e-01,  2.84474515e-01,\n",
      "         1.77248825e-01,  5.92354092e-02, -2.61598669e-01,\n",
      "        -2.37475901e-01,  3.13196296e-01,  1.67918166e-01,\n",
      "         9.96345412e-02,  7.19691634e-02, -1.70648937e-01,\n",
      "        -1.23436342e-01, -5.12975673e-02, -1.90772584e-01,\n",
      "         1.73453684e-01,  6.00013539e-02, -1.51361740e-01,\n",
      "        -1.34403241e-01, -1.27595590e-01,  2.83137750e-01],\n",
      "       [-6.86447296e-02, -1.44886364e-01,  1.69269968e-02,\n",
      "        -1.77155410e-01, -2.00324012e-01, -3.12403286e-01,\n",
      "         1.92001379e-01,  9.38071550e-02, -1.72080717e-01,\n",
      "         9.93170038e-03, -2.30781857e-01,  5.61596857e-02,\n",
      "        -4.34141544e-02, -2.21381872e-01,  1.32521231e-01,\n",
      "         1.77824184e-01, -9.24001194e-02, -1.13762859e-01,\n",
      "        -1.10901659e-01, -2.60696003e-01,  2.05796132e-01,\n",
      "        -2.29151027e-01, -8.30244104e-02,  1.84910528e-01,\n",
      "         2.56658854e-01,  1.73832373e-01,  5.91700446e-02,\n",
      "         1.06951697e-01, -2.77983276e-01,  1.29588276e-01,\n",
      "         1.55846162e-01,  2.35744190e-01,  1.03201047e-01,\n",
      "         3.95198525e-01, -2.58849459e-01,  7.53414044e-02,\n",
      "        -5.20205589e-02, -6.99964400e-02,  1.42817802e-01,\n",
      "        -3.61158392e-01,  1.31936161e-01,  2.83125062e-01,\n",
      "        -3.16854693e-01,  1.24788836e-01,  2.98793905e-01,\n",
      "         1.14803259e-01,  2.79451035e-01, -2.78939672e-01,\n",
      "         1.43555521e-01,  1.84854087e-01, -2.62945133e-01,\n",
      "         3.56176851e-02, -2.14680352e-01,  1.76657333e-01,\n",
      "        -4.74476784e-01, -4.46696602e-02,  2.22219123e-01,\n",
      "         1.66795830e-01, -2.51930867e-01,  1.28047605e-01]]), 'b2': array([[-0.20377129],\n",
      "       [ 0.03259143],\n",
      "       [ 0.07767665],\n",
      "       [-0.05291966],\n",
      "       [-0.03121673],\n",
      "       [ 0.25268576],\n",
      "       [-0.00380257],\n",
      "       [ 0.11184997],\n",
      "       [-0.18221496],\n",
      "       [-0.0008786 ]])}\n"
     ]
    }
   ],
   "source": [
    "print(cls.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.98560280e-05, 1.24157457e-04, 2.32092882e-05, ...,\n",
       "        1.09342873e-03, 2.56809365e-02, 8.71137068e-02],\n",
       "       [3.47473619e-04, 3.44092151e-03, 1.32941094e-04, ...,\n",
       "        7.62678378e-01, 7.41221862e-03, 2.20159892e-01],\n",
       "       [1.06490346e-04, 5.07992952e-05, 1.27572324e-04, ...,\n",
       "        9.67934781e-01, 3.74480558e-04, 3.07466056e-02],\n",
       "       ...,\n",
       "       [2.65344542e-03, 4.41191257e-03, 1.70756326e-02, ...,\n",
       "        6.51544469e-05, 3.20271302e-01, 1.37380840e-03],\n",
       "       [2.13515549e-04, 1.21317269e-05, 5.13402565e-03, ...,\n",
       "        1.20504364e-06, 2.28422285e-03, 1.80441454e-04],\n",
       "       [9.86261530e-01, 2.02985124e-07, 4.07001759e-04, ...,\n",
       "        7.71171000e-05, 2.33094589e-04, 3.43090431e-05]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = cls.predict_proba(X_train)\n",
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat = cls.predict(X_train)\n",
    "Y_test_hat = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903720238095238"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_train, Y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005952380952381"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
