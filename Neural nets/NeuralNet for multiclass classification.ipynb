{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цій практичній роботі ми спробуємо реалізувати нейронну мережу з двох шарів (прихований і вихідний). Запропонований підхід стане заготовкою для реалізації наступних оптимізацій: MBGD, ADAM та регуляризації. \n",
    "\n",
    "Сьогодні ж вам пропонується додати до цього класу підтримку довільної кількості шарів та нейронів в них (наприклад, передавати їх параметром в конструктор, як це робиться в MLPClassifier за допомогою hidden_layer_sizes). Також потрібно передбачити можливість ранньої зупинки ітераційного процесу, якщо значення штрафної функції не покращуватиметься протягом певної кількості ітерацій. Наприклад, якщо протягом $k$ ітерацій штрафна функція за модулем не стане меншою, ніж на поточному кроці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "cm_bright_test = ListedColormap(['#FFA833','#33E0FF']) # '5EFF33', '#FFF933'\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import sklearn.linear_model\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surface(cls, x_1, x_2, ax=None, threshold=0.5, contourf=False):\n",
    "    xx1, xx2 = np.meshgrid(np.linspace(x_1.min(), x_1.max(), 100), \n",
    "                           np.linspace(x_2.min(), x_2.max(), 100))\n",
    "\n",
    "    X_pred = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "    pred = cls.predict_proba(X_pred)[:, 0]\n",
    "    Z = pred.reshape((100, 100))\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.contour(xx1, xx2, Z, levels=[threshold], colors='black')\n",
    "    ax.set_xlim((x_1.min(), x_1.max()))\n",
    "    ax.set_ylim((x_2.min(), x_2.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X, y, color_map=cm_bright):\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(X[:,0], X[:,1], c=(y == 1), cmap=color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxNeuralNet:\n",
    "\n",
    "  def __init__(self, layer_dims, normalize=True, learning_rate=0.01, num_iter=30000, precision=None):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.num_iter = num_iter\n",
    "    self.normalize = normalize\n",
    "    self.layer_dims = layer_dims\n",
    "    self.precision = precision\n",
    "\n",
    "  def __normalize(self, X, mean=None, std=None):\n",
    "    n = X.shape[0]\n",
    "\n",
    "    if mean is None:\n",
    "      mean = np.mean(X, axis=1).reshape((n, 1))\n",
    "\n",
    "    if std is None:\n",
    "      std = np.std(X, axis=1).reshape((n, 1))\n",
    "      \n",
    "    X_new = (X - mean) / std**2\n",
    "    \n",
    "    return X_new, mean, std\n",
    "\n",
    "  def __sigmoid(self, Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "  def __sigmoid_derivative(self, Z):\n",
    "    s = self.__sigmoid(Z)\n",
    "    return s*(1 - s)\n",
    "\n",
    "  def __relu(self, Z):\n",
    "    Z = np.array(Z, copy=True)\n",
    "    Z[Z < 0] = 0\n",
    "    return Z\n",
    "\n",
    "  def __relu_derivative(self, Z):\n",
    "    dZ = np.ones(Z.shape)\n",
    "    dZ[Z <=0 ] = 0\n",
    "    return dZ\n",
    "\n",
    "  def __softmax(self, Z):\n",
    "    eZ = np.exp(Z - np.max(Z))\n",
    "    return eZ / np.sum(eZ, axis=0, keepdims=True)\n",
    "\n",
    "  def __softmax_derivative(self, Z):\n",
    "    #s = softmax.reshape(-1, 1)\n",
    "    return np.diagflat(Z) - np.dot(Z, Z.T)\n",
    "\n",
    "  def __initialize_parameters(self):\n",
    "    layer_dims = self.layer_dims\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "\n",
    "    for l in range(1, L):\n",
    "      parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "      print(parameters['W' + str(l)].shape)\n",
    "      parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "    \n",
    "    self.parameters = parameters\n",
    "\n",
    "  def __forward_linear_activation(self, A_prev, W, b, activation):\n",
    "\n",
    "    # linear forward\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    linear_cache = (A_prev, W, b)\n",
    "\n",
    "    # activation forward\n",
    "    if activation == 'sigmoid':\n",
    "      A = self.__sigmoid(Z)\n",
    "    \n",
    "    if activation == 'relu':\n",
    "      A = self.__relu(Z)\n",
    "    \n",
    "    if activation == 'softmax':\n",
    "      A = self.__softmax(Z)\n",
    "    \n",
    "    activation_cache = Z\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "  def __multilayer_forward(self, X):\n",
    "    parameters = self.parameters\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(1, L):\n",
    "      A_prev = A\n",
    "      A, cache = self.__forward_linear_activation(\n",
    "        A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], activation='sigmoid')\n",
    "      caches.append(cache)\n",
    "\n",
    "    AL, cache = self.__forward_linear_activation(\n",
    "      A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], activation='softmax')\n",
    "    caches.append(cache)\n",
    "\n",
    "    assert(AL.shape == (10, X.shape[1]))\n",
    "    \n",
    "    return AL, caches\n",
    "\n",
    "  def __backward_linear_activation(self, dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    # activation backward\n",
    "    Z = activation_cache\n",
    "    A_prev, W, b = linear_cache\n",
    "    \n",
    "    if activation == 'sigmoid':\n",
    "      dZ = dA * self.__sigmoid_derivative(Z)\n",
    "\n",
    "    if activation == 'relu':\n",
    "      dZ = dA * self.__relu_derivative(Z)\n",
    "\n",
    "    # linear backward\n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1 / m * np.dot(dZ, A_prev.T)\n",
    "    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "  def __multilayer_backward(self, X, Y, caches):\n",
    "    grads = {}\n",
    "    AL = X\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "   \n",
    "    \n",
    "    linear_cache, activation_cache = caches[L-1]\n",
    "    A_prev, W, b = linear_cache\n",
    "    \n",
    "    dZ = AL - Y\n",
    "    m = AL.shape[1]\n",
    "    grads[\"dW\" + str(L)] = 1 / m * np.dot(dZ, A_prev.T)\n",
    "    grads[\"db\" + str(L)] = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    grads[\"dA\" + str(L-1)] = np.dot(W.T, dZ)\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "      current_cache = caches[l]\n",
    "      dA_prev_temp, dW_temp, db_temp = \\\n",
    "        self.__backward_linear_activation(grads[\"dA\" + str(l + 1)], current_cache, activation='sigmoid')\n",
    "      grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "      grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "      grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads\n",
    "\n",
    "  def compute_cost(self, A, Y):\n",
    "    J = -np.mean(Y.T * np.log(A.T+ 1e-8))\n",
    "    return J\n",
    "\n",
    "  def cross_entropy(self, A, Y):\n",
    "    return - np.sum(Y * np.log(A), axis=1)\n",
    "\n",
    "  def __update_parameters(self, grads):\n",
    "    parameters = self.parameters\n",
    "    learning_rate = self.learning_rate\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(L):\n",
    "      parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "      parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "\n",
    "    self.parameters = parameters\n",
    "\n",
    "  def fit(self, X_vert, Y_vert, print_cost=True):\n",
    "\n",
    "    X, Y = X_vert.T, Y_vert.T\n",
    "\n",
    "    if self.normalize:\n",
    "      X, self.__mean, self.__std = self.__normalize(X)\n",
    "\n",
    "    costs = []\n",
    "\n",
    "    self.__initialize_parameters()\n",
    "\n",
    "    for i in range(0, self.num_iter):\n",
    "\n",
    "      AL, caches = self.__multilayer_forward(X)\n",
    "\n",
    "      cost = self.compute_cost(AL, Y)\n",
    "\n",
    "      grads = self.__multilayer_backward(AL, Y, caches)\n",
    "\n",
    "      self.__update_parameters(grads)\n",
    "\n",
    "      if print_cost and i % 10 == 0:\n",
    "        print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "      if print_cost and i % 10 == 0:\n",
    "        costs.append(cost)\n",
    "\n",
    "      if len(costs) > 1 and self.precision != None and np.abs(costs[-2] - costs[-1]) < self.precision:\n",
    "        print('Stopping gradient descent ...')\n",
    "        break\n",
    "\n",
    "    if print_cost:\n",
    "      plt.plot(costs)\n",
    "      plt.ylabel(\"Cost\")\n",
    "      plt.xlabel(\"Iteration, *100\")\n",
    "      plt.show()\n",
    "\n",
    "  def predict_proba(self, X_vert):\n",
    "    X = X_vert.T\n",
    "    if self.normalize:\n",
    "      X, _, _ = self.__normalize(X, self.__mean, self.__std)\n",
    "\n",
    "    probs = self.__multilayer_forward(X)[0]\n",
    "\n",
    "    return probs.T\n",
    "\n",
    "  def predict(self, X_vert):\n",
    "    positive_probs = self.predict_proba(X_vert)\n",
    "    return np.argmax(positive_probs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/large/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X=(42000, 784), y=(42000,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = df.drop('label', axis=1), df['label']\n",
    "print('Training set: X={}, y={}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 784) (4200, 1)\n"
     ]
    }
   ],
   "source": [
    "X, _, Y , _= train_test_split(X, Y.values.reshape((Y.shape[0], 1)), test_size = 0.9, random_state=10)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=10)# Y.values.reshape((Y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 1)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_e = encoder.fit_transform(Y_train).toarray()\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cls = DeepNeuralNet(layer_dims = [2,2,1] , learning_rate = 0.5, num_iter = 4000)\n",
    "#cls = DeepNeuralNet(layer_dims = [2,20,1], normalize = True, learning_rate = 0.5, num_iter = 4000)\n",
    "#cls = DeepNeuralNet(layer_dims = [2,20,1], normalize = True, learning_rate = 0.5, num_iter = 10000)\n",
    "#cls = SoftmaxNeuralNet(layer_dims = [2,20,6,1], normalize = True, learning_rate = 0.5, num_iter = 4000) # easy overfit\n",
    "cls = SoftmaxNeuralNet(layer_dims = [784, 50, 10], normalize = False, learning_rate = 0.1, num_iter = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 784)\n",
      "(10, 50)\n",
      "Cost after iteration 0: 0.230482\n",
      "Cost after iteration 10: 0.229721\n",
      "Cost after iteration 20: 0.229600\n",
      "Cost after iteration 30: 0.229510\n",
      "Cost after iteration 40: 0.229409\n",
      "Cost after iteration 50: 0.229291\n",
      "Cost after iteration 60: 0.229148\n",
      "Cost after iteration 70: 0.228973\n",
      "Cost after iteration 80: 0.228756\n",
      "Cost after iteration 90: 0.228484\n",
      "Cost after iteration 100: 0.228141\n",
      "Cost after iteration 110: 0.227709\n",
      "Cost after iteration 120: 0.227163\n",
      "Cost after iteration 130: 0.226475\n",
      "Cost after iteration 140: 0.225611\n",
      "Cost after iteration 150: 0.224531\n",
      "Cost after iteration 160: 0.223191\n",
      "Cost after iteration 170: 0.221544\n",
      "Cost after iteration 180: 0.219542\n",
      "Cost after iteration 190: 0.217140\n",
      "Cost after iteration 200: 0.214300\n",
      "Cost after iteration 210: 0.211001\n",
      "Cost after iteration 220: 0.207239\n",
      "Cost after iteration 230: 0.203037\n",
      "Cost after iteration 240: 0.198442\n",
      "Cost after iteration 250: 0.193525\n",
      "Cost after iteration 260: 0.188376\n",
      "Cost after iteration 270: 0.183088\n",
      "Cost after iteration 280: 0.177755\n",
      "Cost after iteration 290: 0.172455\n",
      "Cost after iteration 300: 0.167251\n",
      "Cost after iteration 310: 0.162187\n",
      "Cost after iteration 320: 0.157293\n",
      "Cost after iteration 330: 0.152587\n",
      "Cost after iteration 340: 0.148077\n",
      "Cost after iteration 350: 0.143768\n",
      "Cost after iteration 360: 0.139657\n",
      "Cost after iteration 370: 0.135743\n",
      "Cost after iteration 380: 0.132020\n",
      "Cost after iteration 390: 0.128481\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.fit(X_train, Y_train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-0.00839219,  0.01416906, -0.00706121, ...,  0.01755904,\n",
      "        -0.00946638,  0.00300561],\n",
      "       [-0.00344444, -0.00556925,  0.01964895, ..., -0.00408365,\n",
      "         0.00172254,  0.01146754],\n",
      "       [ 0.00679131, -0.005432  , -0.00116377, ...,  0.00328771,\n",
      "        -0.00206861, -0.00338602],\n",
      "       ...,\n",
      "       [-0.01012739, -0.01152303, -0.01012275, ..., -0.00416199,\n",
      "        -0.00688576, -0.00686039],\n",
      "       [ 0.01953656, -0.00683845,  0.00933688, ...,  0.01754095,\n",
      "         0.00164687, -0.00896608],\n",
      "       [ 0.01604378, -0.01791555, -0.01157881, ...,  0.00057121,\n",
      "        -0.00499538, -0.00542883]]), 'b1': array([[-0.00861435],\n",
      "       [ 0.03614378],\n",
      "       [-0.02273904],\n",
      "       [-0.00141311],\n",
      "       [-0.02153201],\n",
      "       [ 0.01108877],\n",
      "       [-0.00478524],\n",
      "       [ 0.04840529],\n",
      "       [-0.01180399],\n",
      "       [ 0.0374652 ],\n",
      "       [-0.0408806 ],\n",
      "       [-0.00359299],\n",
      "       [-0.01595216],\n",
      "       [ 0.03622278],\n",
      "       [ 0.00600686],\n",
      "       [ 0.00752608],\n",
      "       [ 0.02531751],\n",
      "       [-0.01344726],\n",
      "       [ 0.00962874],\n",
      "       [ 0.04562317]]), 'W2': array([[ 0.29481748, -0.48352647,  0.2542953 ,  0.11027795,  0.53248267,\n",
      "        -0.20750691,  0.10901246, -0.67885415,  0.26345523, -0.50663882,\n",
      "         0.488628  ,  0.15507833,  0.27948241, -0.45017505, -0.26491956,\n",
      "        -0.23486724, -0.46370673,  0.41318874, -0.21000691, -0.49473489],\n",
      "       [-0.51240486,  0.36682378, -0.49239675,  0.10718567, -0.63528984,\n",
      "         0.56936145,  0.17270039,  0.30045179, -0.03254442,  0.35221721,\n",
      "        -0.31376536, -0.45592606, -0.33807809,  0.25527799,  0.21969684,\n",
      "         0.34947502,  0.44703455, -0.41829442,  0.06903067,  0.44505572],\n",
      "       [-0.02348094,  0.17636395,  0.10248808, -0.01288912, -0.24068726,\n",
      "         0.04868052,  0.34845826, -0.12355989,  0.29108659, -0.15608136,\n",
      "         0.15854894, -0.30270443,  0.16741104, -0.15887647,  0.32287252,\n",
      "        -0.09276589, -0.06242981, -0.23907574,  0.08028239, -0.17170846],\n",
      "       [-0.16507686, -0.32272651, -0.30763717,  0.34302405, -0.1339559 ,\n",
      "        -0.064234  ,  0.3648294 ,  0.13599918,  0.1529539 , -0.18894775,\n",
      "         0.21541955, -0.01817575, -0.01008239, -0.25776934, -0.09791547,\n",
      "         0.13649243,  0.23647294, -0.00699246,  0.16335437,  0.20542412],\n",
      "       [ 0.20129291,  0.15573276,  0.26705648, -0.28389091,  0.0952409 ,\n",
      "        -0.12861726, -0.39354043,  0.14029177, -0.24734795,  0.14970125,\n",
      "        -0.21538825,  0.18259999, -0.05145695,  0.28749216,  0.04012836,\n",
      "        -0.16337183, -0.18104457,  0.05008154,  0.04477503, -0.05639771],\n",
      "       [ 0.05787398, -0.18867951, -0.02433636,  0.06767611,  0.09223895,\n",
      "        -0.05359319,  0.05269987, -0.07957875,  0.04664294, -0.14170247,\n",
      "         0.22173988,  0.06944253,  0.02610927, -0.1616313 , -0.13659464,\n",
      "         0.01996106, -0.02588296,  0.16002706, -0.00817119, -0.04177746],\n",
      "       [ 0.23135485,  0.23833754,  0.4992163 , -0.23376885, -0.01594462,\n",
      "         0.04136788, -0.14492755, -0.22831635,  0.19036078, -0.1619666 ,\n",
      "         0.13769964, -0.1559052 ,  0.14802146, -0.09388767,  0.4662922 ,\n",
      "        -0.14404359, -0.29305952, -0.17913472, -0.23838043, -0.37037496],\n",
      "       [-0.04096561, -0.05063914, -0.16861822,  0.01022458,  0.2448661 ,\n",
      "        -0.01545527, -0.27040837,  0.26131105, -0.35142513,  0.29013469,\n",
      "        -0.54033479,  0.343282  , -0.06629273,  0.2136249 , -0.35714623,\n",
      "         0.07212041,  0.1421308 ,  0.1699498 ,  0.03490279,  0.41327764],\n",
      "       [-0.08579161,  0.02205298, -0.11852558,  0.06185517, -0.10958476,\n",
      "        -0.05651605,  0.10203577,  0.10805595,  0.02635867,  0.10637203,\n",
      "         0.13679238, -0.11753093, -0.01728538,  0.02088788, -0.0398776 ,\n",
      "         0.12978439,  0.12901775, -0.05979434,  0.01491682, -0.02182699],\n",
      "       [ 0.05768723,  0.11378411,  0.00908505, -0.20809666,  0.12716955,\n",
      "        -0.11456246, -0.3688742 ,  0.23306255, -0.310683  ,  0.26007306,\n",
      "        -0.31933648,  0.23714128, -0.09381805,  0.30709759, -0.14462821,\n",
      "        -0.03097809,  0.04069806,  0.13542081,  0.01765727,  0.10845532]]), 'b2': array([[-0.06274523],\n",
      "       [-0.11966532],\n",
      "       [ 0.01710199],\n",
      "       [-0.02455135],\n",
      "       [ 0.04875825],\n",
      "       [ 0.02178604],\n",
      "       [ 0.0936236 ],\n",
      "       [-0.03221486],\n",
      "       [ 0.02696339],\n",
      "       [ 0.03094349]])}\n"
     ]
    }
   ],
   "source": [
    "print(cls.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01002895, 0.43727063, 0.14095753, ..., 0.02446667, 0.10788089,\n",
       "        0.02267178],\n",
       "       [0.09722469, 0.02104   , 0.05357122, ..., 0.12114652, 0.10721245,\n",
       "        0.14823438],\n",
       "       [0.00448053, 0.09546181, 0.03326255, ..., 0.29110863, 0.05866086,\n",
       "        0.23998722],\n",
       "       ...,\n",
       "       [0.00116758, 0.75763023, 0.04141296, ..., 0.03265859, 0.04646161,\n",
       "        0.02112557],\n",
       "       [0.2833916 , 0.00387848, 0.11961016, ..., 0.01826087, 0.07708065,\n",
       "        0.03438859],\n",
       "       [0.32182866, 0.01122246, 0.10922897, ..., 0.02856354, 0.10348068,\n",
       "        0.03041478]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = cls.predict_proba(X_train)\n",
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat = cls.predict(X_train)\n",
    "Y_test_hat = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735119047619048"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_train, Y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6535714285714286"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
