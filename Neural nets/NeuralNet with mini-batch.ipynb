{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цій практичній роботі ми спробуємо реалізувати нейронну мережу з двох шарів (прихований і вихідний). Запропонований підхід стане заготовкою для реалізації наступних оптимізацій: MBGD, ADAM та регуляризації. \n",
    "\n",
    "Сьогодні ж вам пропонується додати до цього класу підтримку довільної кількості шарів та нейронів в них (наприклад, передавати їх параметром в конструктор, як це робиться в MLPClassifier за допомогою hidden_layer_sizes). Також потрібно передбачити можливість ранньої зупинки ітераційного процесу, якщо значення штрафної функції не покращуватиметься протягом певної кількості ітерацій. Наприклад, якщо протягом $k$ ітерацій штрафна функція за модулем не стане меншою, ніж на поточному кроці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import sklearn.linear_model\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchNeuralNet:\n",
    "\n",
    "    def __init__(self, layer_dims, normalize=True, learning_rate=0.01, \\\n",
    "                  num_iter=30000, precision=None, mini_batch_size=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iter = num_iter\n",
    "        self.normalize = normalize\n",
    "        self.layer_dims = layer_dims\n",
    "        self.precision = precision\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "\n",
    "    def __normalize(self, X, mean=None, std=None):\n",
    "        n = X.shape[0]\n",
    "\n",
    "        if mean is None:\n",
    "            mean = np.mean(X, axis=1).reshape((n, 1))\n",
    "\n",
    "        if std is None:\n",
    "            std = np.std(X, axis=1).reshape((n, 1))\n",
    "      \n",
    "        X_new = (X - mean) / std**2\n",
    "    \n",
    "        return X_new, mean, std\n",
    "\n",
    "    def __sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "    def __sigmoid_derivative(self, Z):\n",
    "        s = self.__sigmoid(Z)\n",
    "        return s*(1 - s)\n",
    "\n",
    "    def __relu(self, Z):\n",
    "        Z = np.array(Z, copy=True)\n",
    "        Z[Z < 0] = 0\n",
    "        return Z\n",
    "\n",
    "    def __relu_derivative(self, Z):\n",
    "        dZ = np.ones(Z.shape)\n",
    "        dZ[Z < 0 ] = 0\n",
    "        return dZ\n",
    "\n",
    "    def __tanh(self, Z):\n",
    "        return np.tanh(Z)\n",
    "\n",
    "    def __tanh_derivative(self, Z):\n",
    "        return 1 / np.power(np.cosh(Z), 2)\n",
    "\n",
    "    def __softmax(self, Z):\n",
    "        eZ = np.exp(Z - np.max(Z))\n",
    "        return eZ / np.sum(eZ, axis=0, keepdims=True)\n",
    "\n",
    "    def __initialize_parameters(self):\n",
    "        layer_dims = self.layer_dims\n",
    "        parameters = {}\n",
    "        L = len(layer_dims)\n",
    "\n",
    "        for l in range(1, L):\n",
    "            parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "            print(parameters['W' + str(l)].shape)\n",
    "            parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "    \n",
    "        self.parameters = parameters\n",
    "\n",
    "    def __forward_linear_activation(self, A_prev, W, b, activation):\n",
    "\n",
    "        # linear forward\n",
    "        Z = np.dot(W, A_prev) + b\n",
    "        linear_cache = (A_prev, W, b)\n",
    "\n",
    "        # activation forward\n",
    "        if activation == 'sigmoid':\n",
    "            A = self.__sigmoid(Z)\n",
    "    \n",
    "        if activation == 'relu':\n",
    "            A = self.__relu(Z)\n",
    "    \n",
    "        if activation == 'softmax':\n",
    "            A = self.__softmax(Z)\n",
    "\n",
    "        if activation == 'tanh':\n",
    "            A = self.__tanh(Z)\n",
    "    \n",
    "        activation_cache = Z\n",
    "\n",
    "        cache = (linear_cache, activation_cache)\n",
    "\n",
    "        return A, cache\n",
    "\n",
    "    def __multilayer_forward(self, X):\n",
    "        parameters = self.parameters\n",
    "        caches = []\n",
    "        A = X\n",
    "        L = len(parameters) // 2\n",
    "\n",
    "        for l in range(1, L):\n",
    "            A_prev = A\n",
    "            A, cache = self.__forward_linear_activation(\n",
    "              A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], activation='tanh')\n",
    "            caches.append(cache)\n",
    "\n",
    "        AL, cache = self.__forward_linear_activation(\n",
    "          A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], activation='softmax')\n",
    "        caches.append(cache)\n",
    "\n",
    "        #assert(AL.shape == (10, X.shape[1]))\n",
    "    \n",
    "        return AL, caches\n",
    "\n",
    "    def __backward_linear_activation(self, dA, cache, activation):\n",
    "\n",
    "        linear_cache, activation_cache = cache\n",
    "\n",
    "        # activation backward\n",
    "        Z = activation_cache\n",
    "        A_prev, W, b = linear_cache\n",
    "    \n",
    "        if activation == 'sigmoid':\n",
    "            dZ = dA * self.__sigmoid_derivative(Z)\n",
    "\n",
    "        if activation == 'relu':\n",
    "            dZ = dA * self.__relu_derivative(Z)\n",
    "\n",
    "        if activation == 'tanh':\n",
    "            dZ = dA * self.__tanh_derivative(Z)\n",
    "\n",
    "        # linear backward\n",
    "        A_prev, W, b = linear_cache\n",
    "        m = A_prev.shape[1]\n",
    "        dW = 1 / m * np.dot(dZ, A_prev.T)\n",
    "        db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "        return dA_prev, dW, db\n",
    "\n",
    "    def __multilayer_backward(self, X, Y, caches):\n",
    "        grads = {}\n",
    "        AL = X\n",
    "        L = len(caches)\n",
    "        m = AL.shape[1]\n",
    "        Y = Y.reshape(AL.shape)\n",
    "\n",
    "\n",
    "        linear_cache, activation_cache = caches[L-1]\n",
    "        A_prev, W, b = linear_cache\n",
    "\n",
    "        dZ = AL - Y\n",
    "        m = AL.shape[1]\n",
    "        grads[\"dW\" + str(L)] = 1 / m * np.dot(dZ, A_prev.T)\n",
    "        grads[\"db\" + str(L)] = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        grads[\"dA\" + str(L-1)] = np.dot(W.T, dZ)\n",
    "\n",
    "        for l in reversed(range(L-1)):\n",
    "            current_cache = caches[l]\n",
    "            dA_prev_temp, dW_temp, db_temp = \\\n",
    "              self.__backward_linear_activation(grads[\"dA\" + str(l + 1)], current_cache, activation='tanh')\n",
    "            grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "            grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "            grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def compute_cost(self, A, Y):\n",
    "        J = -np.mean(Y.T * np.log(A.T+ 1e-8))\n",
    "        return J\n",
    "\n",
    "    def cross_entropy(self, A, Y):\n",
    "        return - np.sum(Y * np.log(A), axis=1)\n",
    "\n",
    "    def __update_parameters(self, grads):\n",
    "        parameters = self.parameters\n",
    "        learning_rate = self.learning_rate\n",
    "        L = len(parameters) // 2\n",
    "\n",
    "        for l in range(L):\n",
    "            parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "            parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def __random_mini_batches(self, X, Y):            \n",
    "        m = X.shape[1]\n",
    "        mini_batches = []\n",
    "        mini_batch_size = self.mini_batch_size if self.mini_batch_size != None else m\n",
    "        \n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_X = X[:, permutation]\n",
    "        \n",
    "        shuffled_Y = Y[:, permutation]\n",
    "\n",
    "        num_complete_minibatches = int(np.floor(m/mini_batch_size))\n",
    "        for k in range(0, num_complete_minibatches):\n",
    "            mini_batch_X = shuffled_X[:, k*mini_batch_size : (k + 1)*mini_batch_size]\n",
    "            mini_batch_Y = shuffled_Y[:, k*mini_batch_size : (k + 1)*mini_batch_size]\n",
    "            \n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "\n",
    "        if m % mini_batch_size != 0:\n",
    "            mini_batch_X = shuffled_X[:, k*mini_batch_size:]\n",
    "            mini_batch_Y = shuffled_Y[:, k*mini_batch_size:]\n",
    "            \n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "\n",
    "        return mini_batches\n",
    "\n",
    "    def __gradient_descent(self, X, Y, print_cost=False):\n",
    "        m = X.shape[1]\n",
    "        costs = []\n",
    "\n",
    "        for i in range(0, self.num_iter):\n",
    "            mini_batches = self.__random_mini_batches(X, Y)\n",
    "            #iteration_cost = 0\n",
    "        \n",
    "            for (mini_X, mini_Y) in mini_batches:\n",
    "\n",
    "                AL, caches = self.__multilayer_forward(mini_X)\n",
    "\n",
    "                #iteration_cost += self.compute_cost(AL, mini_Y)\n",
    "                cost = self.compute_cost(AL, mini_Y)\n",
    "\n",
    "                grads = self.__multilayer_backward(AL, mini_Y, caches)\n",
    "\n",
    "                self.__update_parameters(grads)\n",
    "            \n",
    "            #cost = iteration_cost/m\n",
    "            costs.append(cost)\n",
    "            if print_cost and i % 10 == 0:\n",
    "                print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "\n",
    "            if len(costs) > 1 and self.precision != None and np.abs(costs[-2] - costs[-1]) < self.precision:\n",
    "                print('Stopping gradient descent ...')\n",
    "                break\n",
    "\n",
    "        if print_cost:\n",
    "            plt.plot(costs)\n",
    "            plt.ylabel(\"Cost\")\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.show()\n",
    "    \n",
    "    def fit(self, X_vert, Y_vert, print_cost=True):\n",
    "\n",
    "        X, Y = X_vert.T, Y_vert.T\n",
    "\n",
    "        if self.normalize:\n",
    "            X, self.__mean, self.__std = self.__normalize(X)\n",
    "\n",
    "        self.__initialize_parameters()\n",
    "        \n",
    "        print(X.shape, Y.shape)\n",
    "        \n",
    "        self.__gradient_descent(X, Y, print_cost)\n",
    "\n",
    "    \n",
    "    def predict_proba(self, X_vert):\n",
    "        X = X_vert.T\n",
    "        if self.normalize:\n",
    "            X, _, _ = self.__normalize(X, self.__mean, self.__std)\n",
    "\n",
    "        probs = self.__multilayer_forward(X)[0]\n",
    "\n",
    "        return probs.T\n",
    "\n",
    "    def predict(self, X_vert):\n",
    "        positive_probs = self.predict_proba(X_vert)\n",
    "        return np.argmax(positive_probs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/large/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X=(42000, 784), y=(42000,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = df.drop('label', axis=1), df['label']\n",
    "print('Training set: X={}, y={}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, _, Y , _= train_test_split(X, Y.values.reshape((Y.shape[0], 1)), test_size = 0.9, random_state=10)\n",
    "#print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X.to_numpy(), Y.values.reshape((Y.shape[0], 1)), test_size = 0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_e = encoder.fit_transform(Y_train).toarray()\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = MiniBatchNeuralNet(layer_dims = [784, 60, 10], learning_rate = 0.1, num_iter = 100, \\\n",
    "                         normalize = False, mini_batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 784)\n",
      "(10, 60)\n",
      "(784, 33600) (10, 33600)\n",
      "Cost after iteration 0: 0.227285\n",
      "Cost after iteration 10: 0.060287\n",
      "Cost after iteration 20: 0.040332\n",
      "Cost after iteration 30: 0.032493\n",
      "Cost after iteration 40: 0.029117\n",
      "Cost after iteration 50: 0.027907\n",
      "Cost after iteration 60: 0.023364\n",
      "Cost after iteration 70: 0.023953\n",
      "Cost after iteration 80: 0.021311\n",
      "Cost after iteration 90: 0.023726\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.fit(X_train, Y_train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[ 1.62434536e-02, -6.11756414e-03, -5.28171752e-03, ...,\n",
      "        -1.10657307e-02, -3.59224096e-03,  5.05381903e-03],\n",
      "       [ 1.21794090e-02, -1.94068096e-02, -8.06178212e-03, ...,\n",
      "         2.07229946e-03, -1.43403073e-02,  6.26906306e-03],\n",
      "       [ 2.99825202e-03, -1.85664142e-02, -2.15104316e-02, ...,\n",
      "        -1.95419182e-02,  1.86223746e-03, -3.82994307e-05],\n",
      "       ...,\n",
      "       [ 7.85812220e-03,  6.57456795e-03,  6.37326204e-03, ...,\n",
      "         9.56189284e-03,  1.18337456e-02,  2.18726377e-02],\n",
      "       [-1.07996566e-02, -1.49725917e-03,  1.39717091e-02, ...,\n",
      "        -7.61156529e-03,  1.28740460e-02,  6.56379966e-03],\n",
      "       [ 9.54058572e-03,  1.03352868e-03,  7.60558905e-03, ...,\n",
      "         1.26743192e-03,  1.98366136e-03,  1.17245461e-02]]), 'b1': array([[ 0.06891231],\n",
      "       [-0.09719779],\n",
      "       [ 0.16263022],\n",
      "       [ 0.12068611],\n",
      "       [ 0.1602054 ],\n",
      "       [-0.16146674],\n",
      "       [-0.07360927],\n",
      "       [ 0.1036668 ],\n",
      "       [-0.1085574 ],\n",
      "       [ 0.00117837],\n",
      "       [ 0.01198358],\n",
      "       [ 0.11123101],\n",
      "       [-0.11595538],\n",
      "       [ 0.06757226],\n",
      "       [ 0.04179079],\n",
      "       [-0.05544036],\n",
      "       [ 0.04742943],\n",
      "       [-0.09772994],\n",
      "       [-0.13397686],\n",
      "       [-0.07449352],\n",
      "       [-0.00786279],\n",
      "       [ 0.03623613],\n",
      "       [ 0.02170287],\n",
      "       [-0.10836761],\n",
      "       [-0.06070386],\n",
      "       [-0.12635641],\n",
      "       [ 0.05598345],\n",
      "       [-0.03357729],\n",
      "       [-0.01160177],\n",
      "       [ 0.00785239],\n",
      "       [-0.07578476],\n",
      "       [ 0.08518854],\n",
      "       [-0.00045927],\n",
      "       [-0.04863685],\n",
      "       [-0.09734589],\n",
      "       [-0.17267868],\n",
      "       [ 0.09959577],\n",
      "       [ 0.08290384],\n",
      "       [ 0.09876519],\n",
      "       [-0.01769933],\n",
      "       [ 0.0025009 ],\n",
      "       [-0.12364368],\n",
      "       [ 0.06537349],\n",
      "       [-0.11597959],\n",
      "       [ 0.10016987],\n",
      "       [-0.08569322],\n",
      "       [-0.23706263],\n",
      "       [-0.04815671],\n",
      "       [-0.05781581],\n",
      "       [-0.06640029],\n",
      "       [ 0.12593195],\n",
      "       [ 0.06978668],\n",
      "       [ 0.11211071],\n",
      "       [ 0.11291406],\n",
      "       [-0.09765121],\n",
      "       [-0.0104538 ],\n",
      "       [ 0.07648479],\n",
      "       [ 0.08318941],\n",
      "       [ 0.0053425 ],\n",
      "       [-0.11405614]]), 'W2': array([[ 1.58588020e-01,  2.17151625e-01, -3.30863074e-01,\n",
      "         5.12509959e-01, -2.16336564e-01,  3.01006605e-01,\n",
      "         1.44332238e-01, -4.73954267e-03,  1.40064491e-01,\n",
      "         1.00370162e-01, -1.64475233e-01,  9.99851374e-02,\n",
      "        -3.58107772e-01, -1.58467265e-01, -2.24338797e-01,\n",
      "        -7.36462538e-02,  2.77648997e-01,  6.75045802e-01,\n",
      "         6.96229679e-01,  2.68000301e-01,  7.88886394e-02,\n",
      "         4.53042373e-01, -2.62785001e-02, -1.42123595e-01,\n",
      "        -7.86807640e-02, -3.93130421e-01, -3.88341239e-01,\n",
      "         5.24133362e-01,  2.93291356e-01,  1.37764457e-01,\n",
      "         1.84890247e-01,  4.24659018e-02, -4.61373023e-01,\n",
      "        -1.35014381e-01,  3.72107049e-01, -5.86609881e-02,\n",
      "         2.23242278e-02, -3.03217619e-01, -9.16227681e-02,\n",
      "         1.39723679e-01, -4.70192352e-02, -4.66755855e-01,\n",
      "         1.72966294e-01,  2.80328794e-01,  1.15323320e-01,\n",
      "         2.35833189e-02, -2.17100883e-01, -3.34376421e-01,\n",
      "        -3.54953790e-01,  9.55488635e-02,  2.39421212e-01,\n",
      "        -2.58180855e-01, -2.90964147e-01,  2.79226838e-01,\n",
      "        -2.11971306e-01,  5.16705654e-02,  2.85245199e-01,\n",
      "        -4.43331785e-01,  9.77170080e-02, -3.92784707e-01],\n",
      "       [-5.12133831e-01, -3.50478185e-01,  2.68191361e-01,\n",
      "        -4.47931051e-02,  4.10457870e-01,  7.91356513e-02,\n",
      "        -3.78053674e-01, -2.40695537e-01,  6.80758947e-05,\n",
      "        -1.86632016e-01,  2.40258460e-01, -1.62479340e-01,\n",
      "         3.18635992e-01,  4.23763399e-01,  1.35520146e-01,\n",
      "        -2.32259323e-01,  6.23310478e-01, -2.10846782e-01,\n",
      "        -2.31950602e-01, -4.29909491e-01, -4.05567507e-01,\n",
      "        -5.17139653e-02,  3.84811312e-01,  2.52300096e-01,\n",
      "        -2.56178640e-01, -1.99941798e-01,  3.64640519e-01,\n",
      "        -1.27963565e-01, -2.15458636e-01, -4.82206463e-01,\n",
      "        -4.93624825e-01, -1.60519206e-01,  2.00545884e-01,\n",
      "        -1.47968998e-01,  1.10818289e-02,  2.86530671e-01,\n",
      "        -1.46304550e-01, -3.70116228e-02,  3.61850875e-01,\n",
      "        -4.40643997e-01, -3.88563884e-01,  1.88338395e-01,\n",
      "         4.40059558e-01, -3.43852345e-01,  8.26633878e-02,\n",
      "        -3.24117129e-01,  7.74401124e-02,  2.25152451e-01,\n",
      "         6.58528145e-02,  9.49382443e-02,  9.74472648e-02,\n",
      "        -2.64816215e-02,  3.29821456e-01, -1.96072734e-01,\n",
      "         2.31594385e-01, -1.38770203e-01, -2.82892273e-01,\n",
      "         2.72347437e-01,  3.43902657e-01,  1.62086408e-01],\n",
      "       [ 4.88518851e-01,  2.73370334e-01, -4.79052298e-01,\n",
      "        -2.97042882e-01,  2.32119287e-01,  3.25372281e-01,\n",
      "        -7.15555397e-02,  1.74958761e-01,  7.28841013e-02,\n",
      "         1.61978305e-01,  6.57693291e-01, -2.11990023e-01,\n",
      "         2.49572252e-01,  6.05139129e-01,  2.52315525e-02,\n",
      "         7.84431944e-02, -4.71284487e-01,  1.17438650e-01,\n",
      "         1.29405938e-01,  3.38318587e-01, -3.30512849e-01,\n",
      "         3.76741993e-01,  3.88165271e-01,  1.40334761e-02,\n",
      "        -9.45993537e-02,  3.20108044e-01, -3.08877922e-01,\n",
      "         3.50852836e-01,  1.28137040e-01, -1.53981137e-01,\n",
      "         4.48911343e-01, -2.89739260e-01, -2.37192157e-01,\n",
      "        -1.54055152e-01,  2.52911621e-01, -1.99467398e-01,\n",
      "         5.57433669e-01,  1.84232230e-01, -9.68932332e-02,\n",
      "         2.25931805e-01, -1.70973719e-01, -1.73649093e-01,\n",
      "        -3.06988478e-01,  1.79765316e-01, -2.71608992e-01,\n",
      "         5.12103838e-01,  2.04087828e-01,  2.29899745e-01,\n",
      "        -3.35877167e-01,  1.49318534e-01,  1.35977289e-01,\n",
      "        -1.46628552e-01,  2.12952061e-01, -4.00356039e-01,\n",
      "         2.56751680e-01,  1.41730616e-01, -3.38614687e-01,\n",
      "         1.96348737e-01,  5.00213130e-01,  1.90184121e-01],\n",
      "       [ 5.21132587e-01,  7.61146297e-02,  4.15267281e-01,\n",
      "         6.81041856e-02, -1.11265620e-01, -1.39211224e-01,\n",
      "        -2.91020586e-01, -6.10695650e-01, -5.23959083e-02,\n",
      "         2.50360232e-01, -2.03250128e-02,  1.02394287e-01,\n",
      "         3.11052048e-01, -3.40674689e-01,  1.96334964e-01,\n",
      "         2.91332868e-02, -2.01934261e-01, -1.35068623e-01,\n",
      "        -3.10091022e-01,  1.97218560e-01, -6.74971075e-01,\n",
      "         2.23783735e-01, -2.75390851e-01,  3.47700041e-01,\n",
      "        -2.16837425e-01, -2.41954147e-01,  2.95999579e-01,\n",
      "        -3.58022157e-01,  8.81988465e-02, -5.27972126e-02,\n",
      "         5.53042736e-01, -1.10879261e-01,  3.03004924e-01,\n",
      "        -1.60204204e-01,  2.08093572e-01,  2.41413034e-01,\n",
      "        -1.92358091e-01,  1.22241600e-01, -1.45467935e-01,\n",
      "         1.62606483e-01,  4.29209546e-02, -4.75771396e-01,\n",
      "         9.07316990e-02, -3.70760538e-01,  4.26199772e-01,\n",
      "         5.55712168e-01,  1.16102666e-01,  4.22499423e-01,\n",
      "        -2.67335945e-01,  1.75149891e-01, -6.12332049e-02,\n",
      "        -5.39334103e-02,  1.15391278e-01, -4.81168315e-02,\n",
      "         2.25301670e-01,  2.34861047e-01, -4.24606563e-01,\n",
      "         5.24496775e-01, -1.05188232e-01, -1.66478716e-01],\n",
      "       [-1.45850422e-01, -6.17525517e-03, -2.95777945e-02,\n",
      "        -3.22502066e-01, -1.30114500e-01, -4.17330943e-01,\n",
      "         4.16999136e-01, -3.71023837e-02, -4.57163387e-01,\n",
      "        -8.98204878e-02, -3.16386161e-01,  3.70731524e-01,\n",
      "         3.26472787e-02,  2.91021688e-03,  2.22867896e-01,\n",
      "         2.54760963e-01, -7.14151468e-02,  1.55873509e-02,\n",
      "         2.83907882e-01, -3.63830876e-01,  3.08697154e-01,\n",
      "        -4.36187035e-01, -1.34315996e-01, -5.98349494e-01,\n",
      "        -1.27920937e-01,  2.28619536e-01, -3.54420364e-01,\n",
      "        -3.53897335e-01, -3.44580159e-01, -6.38931327e-02,\n",
      "        -2.92455505e-01, -1.38053026e-01,  9.08550246e-02,\n",
      "         4.06164928e-01, -5.76527448e-01, -2.29970876e-01,\n",
      "        -1.96111652e-01,  2.56920926e-01, -4.85826220e-01,\n",
      "        -9.50682235e-02, -2.62755511e-02,  2.72831984e-01,\n",
      "        -5.02283190e-01,  7.81039068e-03, -4.07209661e-01,\n",
      "         1.28597364e-01, -5.46348578e-01, -4.48406925e-01,\n",
      "         1.61113150e-01, -6.72892757e-01, -3.30233430e-01,\n",
      "         5.25158941e-01, -1.23379336e-01, -9.39393598e-02,\n",
      "         7.68134366e-02, -2.91548769e-03,  1.14042326e-01,\n",
      "         1.30069806e-02, -1.44162635e-01,  2.75191254e-01],\n",
      "       [-1.76014562e-01, -1.01550516e-01,  4.47886909e-01,\n",
      "         2.79376781e-01,  2.07139520e-01, -8.03241084e-02,\n",
      "         5.00968909e-04,  4.66593924e-01,  2.70050756e-01,\n",
      "         2.96607453e-01, -3.70809455e-01,  4.76444686e-02,\n",
      "        -2.46204594e-01, -2.24070115e-01, -6.01793388e-01,\n",
      "        -4.08711336e-01,  1.10857455e-01, -5.27726375e-01,\n",
      "        -4.50597493e-01,  2.76693626e-01,  2.51185003e-01,\n",
      "         1.95677819e-01, -1.26329482e-01, -2.53954866e-01,\n",
      "        -3.38832240e-01, -1.95768294e-01,  3.18429694e-01,\n",
      "        -2.20493473e-01,  6.54089548e-01,  3.89425348e-01,\n",
      "        -1.50042054e-01, -6.18654199e-02, -7.86292849e-02,\n",
      "         2.30588059e-02, -3.59759212e-01, -1.13160632e-01,\n",
      "        -2.76988390e-01,  2.80872927e-01, -2.16043271e-01,\n",
      "         4.16776615e-01,  2.85457939e-01, -5.64672336e-01,\n",
      "         3.00066583e-01, -5.15896881e-02, -3.17908473e-02,\n",
      "        -8.51390475e-01, -2.64127098e-01,  1.44798584e-01,\n",
      "        -3.20790327e-01, -1.20794900e-01,  3.09744277e-01,\n",
      "         3.11968218e-02,  2.97906767e-01,  5.49608650e-01,\n",
      "        -1.52280779e-01,  5.57138452e-02,  2.35685491e-01,\n",
      "        -1.22753636e-01, -2.09465713e-01,  5.48273982e-02],\n",
      "       [-1.05964298e-01,  3.16030577e-01,  5.20556820e-02,\n",
      "        -2.18825627e-01,  3.80579743e-01, -7.47612207e-02,\n",
      "        -5.85531064e-01, -8.98242226e-02,  2.65108403e-01,\n",
      "        -5.98369971e-01,  3.01755789e-01,  3.17407436e-01,\n",
      "        -2.79244008e-01, -1.32687883e-02, -2.29253869e-01,\n",
      "         3.09429500e-01, -4.15951282e-02,  6.09331637e-02,\n",
      "         5.29296060e-01, -3.30183689e-01,  4.25570410e-01,\n",
      "         1.18899407e-01, -5.31771753e-02, -3.65734709e-01,\n",
      "         3.20923374e-01, -1.17199447e-02, -4.58196537e-01,\n",
      "        -1.50798585e-01,  1.27487763e-01, -1.28323636e-01,\n",
      "        -6.33766580e-01, -2.41308753e-02, -2.03711502e-01,\n",
      "         6.99843590e-02,  6.93527859e-01, -1.81704993e-01,\n",
      "         1.68444345e-01,  1.75774658e-01, -1.08691135e-01,\n",
      "         1.32760715e-01, -8.95613801e-02,  2.66329335e-01,\n",
      "        -2.06508049e-01,  2.73829018e-01, -3.85557962e-01,\n",
      "        -1.51315480e-01,  1.51022703e-01,  1.99223246e-01,\n",
      "         3.99913400e-01, -4.05162769e-01,  4.81320201e-01,\n",
      "         1.01826741e-01,  3.61087575e-02, -6.77108459e-02,\n",
      "         4.83829562e-01, -4.94144230e-01,  3.25130472e-01,\n",
      "        -4.99229946e-01,  4.05932718e-01,  5.63435001e-02],\n",
      "       [ 3.22818711e-01, -3.44621769e-01, -6.25916088e-02,\n",
      "         5.15335970e-01,  6.36374432e-02, -2.21414853e-01,\n",
      "         2.06523287e-01,  1.56296290e-01, -5.84152796e-01,\n",
      "        -6.72997617e-02,  3.00101926e-01, -1.75678631e-01,\n",
      "        -3.48013932e-01,  4.19790237e-01,  6.13868925e-01,\n",
      "         6.36761333e-02, -1.13802612e-01,  1.76176838e-01,\n",
      "        -4.53978172e-01,  1.02639049e-01, -2.58642147e-01,\n",
      "        -2.76277703e-01,  1.17499161e-01,  1.56090328e-01,\n",
      "         3.86103967e-01, -1.54507044e-01,  2.46905043e-01,\n",
      "         2.55985925e-01, -4.47013011e-01,  3.63561979e-02,\n",
      "         2.36098607e-01,  6.52998773e-01,  2.02045993e-01,\n",
      "        -4.11582263e-01, -3.83797936e-01, -4.10082550e-01,\n",
      "         5.41709026e-01, -3.19436852e-01,  7.36026189e-01,\n",
      "        -1.58553490e-01,  8.66458297e-02,  3.48197086e-02,\n",
      "         1.38223441e-01, -3.83394355e-01,  3.57913253e-01,\n",
      "         2.91704204e-01, -5.08509181e-01, -2.29780079e-01,\n",
      "         2.68254242e-01,  6.70494319e-02, -3.35040880e-01,\n",
      "         9.81391128e-03, -2.34873727e-01,  1.43762221e-01,\n",
      "        -3.16697168e-01,  1.25451826e-01, -1.12240379e-02,\n",
      "         1.40316636e-01, -4.08699544e-01, -7.31399436e-01],\n",
      "       [-3.33417533e-01,  8.76169501e-02, -4.75337387e-01,\n",
      "        -1.40757162e-01, -4.78913651e-01,  6.19939143e-01,\n",
      "         3.26022645e-01,  7.20846466e-02,  4.81446648e-01,\n",
      "         5.92529891e-02, -2.59347069e-01, -4.57519743e-01,\n",
      "         2.63719589e-01, -2.86134838e-01, -2.49845457e-01,\n",
      "        -2.38240411e-01, -1.18027536e-01, -8.83972961e-02,\n",
      "        -7.53374621e-02,  3.32027091e-01,  2.86224505e-01,\n",
      "        -3.12962219e-01, -1.04400722e-01,  1.79422112e-01,\n",
      "         8.70773937e-02,  3.86831020e-01,  2.58149489e-01,\n",
      "        -4.65590060e-02,  9.05159325e-02,  1.11447093e-01,\n",
      "        -1.07892483e-01, -2.59708652e-01,  9.43241787e-02,\n",
      "        -3.42363944e-02, -1.29789228e-03,  4.07476538e-01,\n",
      "        -2.81425192e-01, -1.87659581e-01, -1.10188257e-01,\n",
      "         2.25089360e-01,  1.30604754e-01,  5.30090555e-01,\n",
      "         2.91598647e-01,  1.08424708e-01, -3.49979096e-01,\n",
      "        -3.02734295e-01,  3.47299541e-01,  1.64723831e-01,\n",
      "         1.71947278e-01,  1.24459930e-01, -2.84131604e-01,\n",
      "        -1.43129390e-01, -1.23520954e-01, -3.82526625e-01,\n",
      "         2.13785129e-01,  5.91455815e-02, -2.07963140e-01,\n",
      "        -2.67840710e-01, -1.98928978e-01,  3.61243850e-01],\n",
      "       [-2.35574165e-01, -1.80190653e-01,  1.25536803e-01,\n",
      "        -3.61223661e-01, -2.89689367e-01, -3.68776842e-01,\n",
      "         2.41129793e-01,  1.35632749e-01, -1.47504452e-01,\n",
      "         6.16247334e-02, -3.78344325e-01,  7.71622936e-02,\n",
      "        -1.57298183e-04, -3.96311990e-01,  1.50706786e-01,\n",
      "         2.46537154e-01, -2.92378205e-02, -1.21557119e-01,\n",
      "        -1.08142321e-01, -3.60732061e-01,  3.21857591e-01,\n",
      "        -2.55071646e-01, -1.31270816e-01,  4.11710989e-01,\n",
      "         3.62114784e-01,  2.48307025e-01,  4.12498775e-03,\n",
      "         1.44933265e-01, -3.36896733e-01,  2.23021704e-01,\n",
      "         2.73124044e-01,  3.24143243e-01,  9.91348072e-02,\n",
      "         5.59458254e-01, -2.08757041e-01,  1.91843313e-01,\n",
      "        -2.25482698e-01, -1.31664376e-01,  2.06673345e-01,\n",
      "        -5.76820893e-01,  1.96421010e-01,  3.70691715e-01,\n",
      "        -4.27173919e-01,  2.35439663e-01,  4.81260587e-01,\n",
      "         1.24567362e-01,  6.25235484e-01, -3.72917446e-01,\n",
      "         1.98806225e-01,  4.60318551e-01, -2.75752580e-01,\n",
      "        -5.38188248e-02, -2.71791494e-01,  2.28499814e-01,\n",
      "        -6.93254439e-01, -5.46108235e-02,  3.25480808e-01,\n",
      "         2.43264090e-01, -3.08558644e-01,  2.02572556e-01]]), 'b2': array([[-0.27369081],\n",
      "       [ 0.07797095],\n",
      "       [ 0.16899928],\n",
      "       [-0.09622248],\n",
      "       [-0.05724374],\n",
      "       [ 0.49374217],\n",
      "       [ 0.00528241],\n",
      "       [ 0.22281082],\n",
      "       [-0.51851005],\n",
      "       [-0.02313855]])}\n"
     ]
    }
   ],
   "source": [
    "print(cls.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.36895627e-07, 3.52639484e-06, 3.77452522e-06, ...,\n",
       "        8.25152571e-05, 7.09171752e-03, 4.01949145e-03],\n",
       "       [1.74735396e-05, 1.41272822e-03, 5.55209013e-05, ...,\n",
       "        7.92479091e-01, 4.79678025e-03, 1.99955436e-01],\n",
       "       [8.78430571e-06, 3.00063780e-06, 1.46028057e-04, ...,\n",
       "        9.92492292e-01, 1.57101948e-04, 6.91952401e-03],\n",
       "       ...,\n",
       "       [4.07106760e-04, 1.63149627e-03, 6.18061647e-03, ...,\n",
       "        9.51039415e-06, 2.00129465e-01, 3.66919831e-04],\n",
       "       [1.58579192e-05, 3.81652773e-07, 8.43110360e-04, ...,\n",
       "        1.13660263e-07, 4.22399772e-04, 4.32185371e-05],\n",
       "       [9.97262909e-01, 3.99153397e-09, 2.66510226e-04, ...,\n",
       "        1.34242333e-05, 3.28376600e-05, 1.04361455e-05]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = cls.predict_proba(X_train)\n",
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat = cls.predict(X_train)\n",
    "Y_test_hat = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941577380952381"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_train, Y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357142857142857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
